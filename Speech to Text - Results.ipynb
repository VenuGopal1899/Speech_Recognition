{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "robust-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "excited-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VenuGopal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\VenuGopal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text pre-processing\n",
    "\"\"\"removes punctuation, stopwords, and returns a list of the remaining words, or tokens\"\"\"\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "comparative-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "import string\n",
    "\n",
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    4. Remove words\n",
    "    '''\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join([i for i in nopunc if not i.isdigit()])\n",
    "    nopunc =  [word.lower() for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "#   Print each chunk\n",
    "#   print([stemmer.lemmatize(word) for word in nopunc]) \n",
    "\n",
    "    return [stemmer.lemmatize(word) for word in nopunc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "seventh-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription(path):\n",
    "    \n",
    "    # Cleaned paragraph from given audio file\n",
    "    cleaned_paragraph = []\n",
    "    \n",
    "    # Get audio file name from given path\n",
    "    # print(path)\n",
    "    audioFileName = path.split('/')[-1]\n",
    "    \n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path, \"flac\")    \n",
    "    \n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "    \n",
    "    # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "    \n",
    "    # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "    \n",
    "    # keep the silence for 500 milli seconds, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    \n",
    "    folder_name = \"audio-chunks\"\n",
    "    \n",
    "    # create a directory to store the audio chunks\n",
    "    \n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "        \n",
    "    whole_text = \"\"\n",
    "    \n",
    "#     # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        \n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        \n",
    "        chunk_filename = os.path.join(folder_name, f\"{audioFileName}-chunk-{i}.flac\")\n",
    "        audio_chunk.export(chunk_filename, format=\"flac\")\n",
    "        \n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            \n",
    "        # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}\"\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                # Print each chunk of audio file\n",
    "\n",
    "                #  print(chunk_filename, \":\", text)\n",
    "\n",
    "                '''\n",
    "                \n",
    "                '''\n",
    "                # Process the transcripted text - Cleaning\n",
    "\n",
    "                #  cleaned_paragraph += text_process(text)\n",
    "\n",
    "                '''            \n",
    "                whole_text += text\n",
    "    \n",
    "    '''\n",
    "    # Print Cleaned Paragraph \n",
    "        \n",
    "    #  print(\"\\nCleaned Paragraph :\\n\",cleaned_paragraph)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # return the text for all chunks detected\n",
    "    \n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "permanent-factory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "Error: \n",
      "Error: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# files_19_198 - List of audio file paths in folder ./19/198/\n",
    "# files_19_227 - List of audio file paths in folder ./19/227/\n",
    "\n",
    "files_19_198 = ['./19/198/' + f for f in os.listdir('./19/198/')[:-1]]\n",
    "files_19_227 = ['./19/227/' + f for f in os.listdir('./19/227/')[:-1]]\n",
    "\n",
    "# print(files_19_198)\n",
    "# print(files_19_227)\n",
    "\n",
    "result_transcription_19_198 = []\n",
    "result_transcription_19_227 = []\n",
    "\n",
    "for eachFilePath in files_19_198:\n",
    "    res = \"\"\n",
    "    wholeText = get_large_audio_transcription(eachFilePath)\n",
    "    # print(eachFilePath.split('/')[-1]+\" :\\n\", wholeText)\n",
    "    result_transcription_19_198 += [res.join(wholeText)]\n",
    "    \n",
    "for eachFilePath in files_19_227:\n",
    "    res = \"\"\n",
    "    wholeText = get_large_audio_transcription(eachFilePath)\n",
    "    # print(eachFilePath.split('/')[-1]+\" :\\n\", wholeText)\n",
    "    result_transcription_19_227 += [res.join(wholeText)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "latin-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_trans_19_198 = result_transcription_19_198\n",
    "res_trans_19_227 = result_transcription_19_227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "discrete-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "strategic-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_transcription_19_198 = np.array(result_transcription_19_198).reshape(38, 1)\n",
    "result_transcription_19_227 = np.array(result_transcription_19_227).reshape(73, 1)\n",
    "\n",
    "df_res_19_198 = pd.DataFrame(result_transcription_19_198)\n",
    "df_res_19_227 = pd.DataFrame(result_transcription_19_227)\n",
    "\n",
    "df_res_19_198.columns = ['Model Transcription']\n",
    "df_res_19_227.columns = ['Model Transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "contained-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_file_19_198 = pd.read_csv(\"./19/198/19-198.trans.txt\", header = None)\n",
    "trans_file_19_227 = pd.read_csv(\"./19/227/19-227.trans.txt\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "roman-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_file_19_198 = []\n",
    "res_file_19_227 = []\n",
    "\n",
    "for each_line in trans_file_19_198[0]:\n",
    "    res_file_19_198 += [each_line.split(' ', 1)]\n",
    "\n",
    "for each_line in trans_file_19_227[0]:\n",
    "    res_file_19_227 += [each_line.split(' ', 1)]\n",
    "    \n",
    "df_19_198 = pd.DataFrame(res_file_19_198)\n",
    "df_19_227 = pd.DataFrame(res_file_19_227)\n",
    "\n",
    "df_19_198.columns = ['File Name', 'Original Transcription']\n",
    "df_19_227.columns = ['File Name', 'Original Transcription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "occupational-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res_19_198 = [df_19_198, df_res_19_198]\n",
    "final_res_19_227 = [df_19_227, df_res_19_227]\n",
    "\n",
    "final_res_19_198 = pd.concat(final_res_19_198, axis=1)\n",
    "final_res_19_227 = pd.concat(final_res_19_227, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "saving-indication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Original Transcription</th>\n",
       "      <th>Model Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19-198-0000</td>\n",
       "      <td>NORTHANGER ABBEY</td>\n",
       "      <td>Northanger abbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19-198-0001</td>\n",
       "      <td>THIS LITTLE WORK WAS FINISHED IN THE YEAR EIGH...</td>\n",
       "      <td>This work was finished in the year 1830And int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19-198-0002</td>\n",
       "      <td>NEITHER THE AUTHOR NOR THE PUBLIC HAVE ANY OTH...</td>\n",
       "      <td>Neither the awesome vinod public have any othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19-198-0003</td>\n",
       "      <td>THE PUBLIC ARE ENTREATED TO BEAR IN MIND THAT ...</td>\n",
       "      <td>Tatha black are interested to bear in mind tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19-198-0004</td>\n",
       "      <td>CHAPTER ONE NO ONE WHO HAD EVER SEEN CATHERINE...</td>\n",
       "      <td>Chapter 1No one had ever seen cancer in mobile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     File Name                             Original Transcription  \\\n",
       "0  19-198-0000                                   NORTHANGER ABBEY   \n",
       "1  19-198-0001  THIS LITTLE WORK WAS FINISHED IN THE YEAR EIGH...   \n",
       "2  19-198-0002  NEITHER THE AUTHOR NOR THE PUBLIC HAVE ANY OTH...   \n",
       "3  19-198-0003  THE PUBLIC ARE ENTREATED TO BEAR IN MIND THAT ...   \n",
       "4  19-198-0004  CHAPTER ONE NO ONE WHO HAD EVER SEEN CATHERINE...   \n",
       "\n",
       "                                 Model Transcription  \n",
       "0                                   Northanger abbey  \n",
       "1  This work was finished in the year 1830And int...  \n",
       "2  Neither the awesome vinod public have any othe...  \n",
       "3  Tatha black are interested to bear in mind tha...  \n",
       "4  Chapter 1No one had ever seen cancer in mobile...  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res_19_198.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "mighty-regard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Original Transcription</th>\n",
       "      <th>Model Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19-227-0000</td>\n",
       "      <td>CHAPTER THIRTY CATHERINE'S DISPOSITION WAS NOT...</td>\n",
       "      <td>Chapter 30762 session was naturally 7:309 habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19-227-0001</td>\n",
       "      <td>HER MOTHER COULD NOT BUT PERCEIVE THEM NOW TO ...</td>\n",
       "      <td>Mother could not receive them now to be greatl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19-227-0002</td>\n",
       "      <td>AND IT SEEMED AS IF SHE COULD EVEN WALK ABOUT ...</td>\n",
       "      <td>Seemed as if she could even walked about the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19-227-0003</td>\n",
       "      <td>BUT WHEN A THIRD NIGHT'S REST HAD NEITHER REST...</td>\n",
       "      <td>The night's rest of the restored hatya for thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19-227-0004</td>\n",
       "      <td>MY DEAR CATHERINE I AM AFRAID YOU ARE GROWING ...</td>\n",
       "      <td>My dear friendI am afraid you are growing quit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     File Name                             Original Transcription  \\\n",
       "0  19-227-0000  CHAPTER THIRTY CATHERINE'S DISPOSITION WAS NOT...   \n",
       "1  19-227-0001  HER MOTHER COULD NOT BUT PERCEIVE THEM NOW TO ...   \n",
       "2  19-227-0002  AND IT SEEMED AS IF SHE COULD EVEN WALK ABOUT ...   \n",
       "3  19-227-0003  BUT WHEN A THIRD NIGHT'S REST HAD NEITHER REST...   \n",
       "4  19-227-0004  MY DEAR CATHERINE I AM AFRAID YOU ARE GROWING ...   \n",
       "\n",
       "                                 Model Transcription  \n",
       "0  Chapter 30762 session was naturally 7:309 habi...  \n",
       "1  Mother could not receive them now to be greatl...  \n",
       "2  Seemed as if she could even walked about the h...  \n",
       "3  The night's rest of the restored hatya for thi...  \n",
       "4  My dear friendI am afraid you are growing quit...  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res_19_227.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "respected-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res_19_198['Model Transcription'] = final_res_19_198['Model Transcription'].str.lower()\n",
    "final_res_19_198['Original Transcription'] = final_res_19_198['Original Transcription'].str.lower() \n",
    "\n",
    "final_res_19_227['Model Transcription'] = final_res_19_227['Model Transcription'].str.lower()\n",
    "final_res_19_227['Original Transcription'] = final_res_19_227['Original Transcription'].str.lower()\n",
    "\n",
    "final_res_19_198.to_csv('./19/Result_19_198.csv')\n",
    "final_res_19_227.to_csv('./19/Result_19_227.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "focused-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART-2, SEQUENCE MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "introductory-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "characteristic-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTranscriptions_19_198 = []\n",
    "originalTranscriptions_19_198 = []\n",
    "sequenceSimilarity_19_198 = []\n",
    "\n",
    "for model_transcription in final_res_19_198['Model Transcription']:\n",
    "    modelTranscriptions_19_198.append(model_transcription)\n",
    "    \n",
    "for original_transcription in final_res_19_198['Original Transcription']:\n",
    "    originalTranscriptions_19_198.append(original_transcription)\n",
    "\n",
    "for i in range(len(modelTranscriptions_19_198)):\n",
    "    sequenceSimilarity_19_198.append(round(SequenceMatcher(None, originalTranscriptions_19_198[i], modelTranscriptions_19_198[i]).ratio(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "guilty-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTranscriptions_19_227 = []\n",
    "originalTranscriptions_19_227 = []\n",
    "sequenceSimilarity_19_227 = []\n",
    "\n",
    "for model_transcription in final_res_19_227['Model Transcription']:\n",
    "    modelTranscriptions_19_227.append(model_transcription)\n",
    "    \n",
    "for original_transcription in final_res_19_227['Original Transcription']:\n",
    "    originalTranscriptions_19_227.append(original_transcription)\n",
    "\n",
    "for i in range(len(modelTranscriptions_19_227)):\n",
    "    sequenceSimilarity_19_227.append(round(SequenceMatcher(None, originalTranscriptions_19_227[i], modelTranscriptions_19_227[i]).ratio(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cultural-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceSimilarity_19_198 = np.array(sequenceSimilarity_19_198).reshape(38, 1)\n",
    "sequenceSimilarity_19_227 = np.array(sequenceSimilarity_19_227).reshape(73, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "passing-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity_19_198 = pd.DataFrame(sequenceSimilarity_19_198)\n",
    "df_similarity_19_227 = pd.DataFrame(sequenceSimilarity_19_227)\n",
    "\n",
    "df_similarity_19_198.columns = ['Sequence Similarity']\n",
    "df_similarity_19_227.columns = ['Sequence Similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "heavy-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "Output_19_198 = [final_res_19_198, df_similarity_19_198]\n",
    "Output_19_198 = pd.concat(Output_19_198, axis = 1)\n",
    "Output_19_198.set_index('File Name', inplace = True)\n",
    "\n",
    "Output_19_227 = [final_res_19_227, df_similarity_19_227]\n",
    "Output_19_227 = pd.concat(Output_19_227, axis = 1)\n",
    "Output_19_227.set_index('File Name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "biblical-greeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Transcription</th>\n",
       "      <th>Model Transcription</th>\n",
       "      <th>Sequence Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-198-0000</th>\n",
       "      <td>northanger abbey</td>\n",
       "      <td>northanger abbey</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-198-0001</th>\n",
       "      <td>this little work was finished in the year eigh...</td>\n",
       "      <td>this work was finished in the year 1830and int...</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-198-0002</th>\n",
       "      <td>neither the author nor the public have any oth...</td>\n",
       "      <td>neither the awesome vinod public have any othe...</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-198-0003</th>\n",
       "      <td>the public are entreated to bear in mind that ...</td>\n",
       "      <td>tatha black are interested to bear in mind tha...</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-198-0004</th>\n",
       "      <td>chapter one no one who had ever seen catherine...</td>\n",
       "      <td>chapter 1no one had ever seen cancer in mobile...</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Original Transcription  \\\n",
       "File Name                                                        \n",
       "19-198-0000                                   northanger abbey   \n",
       "19-198-0001  this little work was finished in the year eigh...   \n",
       "19-198-0002  neither the author nor the public have any oth...   \n",
       "19-198-0003  the public are entreated to bear in mind that ...   \n",
       "19-198-0004  chapter one no one who had ever seen catherine...   \n",
       "\n",
       "                                           Model Transcription  \\\n",
       "File Name                                                        \n",
       "19-198-0000                                   northanger abbey   \n",
       "19-198-0001  this work was finished in the year 1830and int...   \n",
       "19-198-0002  neither the awesome vinod public have any othe...   \n",
       "19-198-0003  tatha black are interested to bear in mind tha...   \n",
       "19-198-0004  chapter 1no one had ever seen cancer in mobile...   \n",
       "\n",
       "             Sequence Similarity  \n",
       "File Name                         \n",
       "19-198-0000                1.000  \n",
       "19-198-0001                0.835  \n",
       "19-198-0002                0.880  \n",
       "19-198-0003                0.028  \n",
       "19-198-0004                0.798  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output_19_198.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "hired-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Transcription</th>\n",
       "      <th>Model Transcription</th>\n",
       "      <th>Sequence Similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19-227-0000</th>\n",
       "      <td>chapter thirty catherine's disposition was not...</td>\n",
       "      <td>chapter 30762 session was naturally 7:309 habi...</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-227-0001</th>\n",
       "      <td>her mother could not but perceive them now to ...</td>\n",
       "      <td>mother could not receive them now to be greatl...</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-227-0002</th>\n",
       "      <td>and it seemed as if she could even walk about ...</td>\n",
       "      <td>seemed as if she could even walked about the h...</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-227-0003</th>\n",
       "      <td>but when a third night's rest had neither rest...</td>\n",
       "      <td>the night's rest of the restored hatya for thi...</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19-227-0004</th>\n",
       "      <td>my dear catherine i am afraid you are growing ...</td>\n",
       "      <td>my dear friendi am afraid you are growing quit...</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Original Transcription  \\\n",
       "File Name                                                        \n",
       "19-227-0000  chapter thirty catherine's disposition was not...   \n",
       "19-227-0001  her mother could not but perceive them now to ...   \n",
       "19-227-0002  and it seemed as if she could even walk about ...   \n",
       "19-227-0003  but when a third night's rest had neither rest...   \n",
       "19-227-0004  my dear catherine i am afraid you are growing ...   \n",
       "\n",
       "                                           Model Transcription  \\\n",
       "File Name                                                        \n",
       "19-227-0000  chapter 30762 session was naturally 7:309 habi...   \n",
       "19-227-0001  mother could not receive them now to be greatl...   \n",
       "19-227-0002  seemed as if she could even walked about the h...   \n",
       "19-227-0003  the night's rest of the restored hatya for thi...   \n",
       "19-227-0004  my dear friendi am afraid you are growing quit...   \n",
       "\n",
       "             Sequence Similarity  \n",
       "File Name                         \n",
       "19-227-0000                0.632  \n",
       "19-227-0001                0.018  \n",
       "19-227-0002                0.866  \n",
       "19-227-0003                0.765  \n",
       "19-227-0004                0.809  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output_19_227.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "disabled-broadway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error - Training Data Set :  0.08906649999999999\n",
      "Mean Squared Error - Test Data Set  :  0.11902001369863012\n"
     ]
    }
   ],
   "source": [
    "MSE_Training_DataSet = np.square(np.subtract(np.ones(sequenceSimilarity_19_198.shape, dtype=int),sequenceSimilarity_19_198)).mean()\n",
    "MSE_Test_DataSet = np.square(np.subtract(np.ones(sequenceSimilarity_19_227.shape, dtype=int),sequenceSimilarity_19_227)).mean()\n",
    "\n",
    "print('Mean Squared Error - Training Data Set : ', MSE_Training_DataSet)\n",
    "print('Mean Squared Error - Test Data Set  : ', MSE_Test_DataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-firewall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
